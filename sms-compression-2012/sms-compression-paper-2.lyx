#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
SMS Compression Paper #2
\end_layout

\begin_layout Section
Things Done / Discovered
\end_layout

\begin_layout Standard
- very compact compressed representation of statistics for use on memory-constra
ined devices.
\end_layout

\begin_layout Standard
- can use compressed statistics while still compressed to enable compression/dec
ompression using only a few KB of RAM for small devices that need to operate
 on only a few messages at a time (eg mobile phone clients).
\end_layout

\begin_layout Standard
- can also extract all statistics for ~100x - 1000x faster operation, in
 return for using a few 10s of MB of RAM for devices that need to operate
 on many messages (eg message centres/exchanges).
\end_layout

\begin_layout Standard
- variable order statistics
\end_layout

\begin_layout Standard
- variable frequency thresholds
\end_layout

\begin_layout Standard
- both of the above affect compression performance.
 Minima for compressed size moves towards larger frequency thresholds as
 order increases.
\end_layout

\begin_layout Standard
- for fixed file budget higher order and higher frequency threshold is the
 best choice.
 This is not surprising, as more deeper modelling should result in better
 performance.
\end_layout

\begin_layout Standard
- deeper modelling reduces dependence on word lists.
\end_layout

\begin_layout Standard
- go too deep (> order 4) and compression starts to decrease (but why?)
\end_layout

\begin_layout Standard
- flattened digits to a single symbol followed by equiprobable(10) to reduce
 node proliferation
\end_layout

\begin_layout Standard
- reduce memory use during stats gathering by having small nodes with 4
 entries each, and only allocating all ~70 nodes when those are full.
 Reduces memory use by approximately 75%.
\end_layout

\begin_layout Section
Things to cover
\end_layout

\begin_layout Standard
- compression apparently improves with increasing message length.
 Is this just because we encode message length statistically, and shorter
 messages are rarer, so end up costing more bits to encode their length?
\end_layout

\begin_layout Standard
- explain the 66% peak (9-digit numbers: 4.9 bytes for digits + ~3bits for
 length > 5 bytes, hence costing 6 bytes) (the 9-digit numbers are an artifact
 of my original dodgy tweet-decoder, the new twitter_corpus5.txt and friends
 deals with this)
\end_layout

\begin_layout Standard
- explain why Order 4 performs better than Order 5, 6 or 7 (see discussion
 below on compressing numbers for one explanation and possible correction).
\end_layout

\begin_layout Standard
- explain ~75% peak (radix-69 encoding)
\end_layout

\begin_layout Standard
- explain 100% peak (things that don't compress)
\end_layout

\begin_layout Standard
- remove all dependence on message_stats.c (except for word lists as an outgoing
 comparison)
\end_layout

\begin_layout Standard
- number compression: represent 0-9 with a single token, followed by explicitly
 coding the digit using [0..9] via range coding.
 Should deal with order4 outperforming order6.
\end_layout

\begin_layout Standard
- unicode compression: represent all unicode characters with a single token,
 followed by explicitly coding the codepoint via range coding.
 Generate stats for each unicode character page (the 512 blocks of 0x80
 chars each).
 Stats should be frequency of each code in the page, plus the the frequency
 of switching to each of the other 511 pages.
 That should capture the probability of page changes fairly well, excepting
 when we have single character excursions to another code page.
 Use 512th page slot to indicate switching back to the previous code page,
 thus dealing with excursions.
 Table size will be 512 pages x (0x80 + 512 = 768) = 384K entries x sizeof(unsig
ned int) = 1.5MB.
 Quite manageable.
\end_layout

\begin_layout Section
Future work
\end_layout

\begin_layout Standard
- higher-order Unicode statistics.
\end_layout

\begin_layout Standard
- Further examine what to do when counts in a given node are too low to
 be trustworthy.
 Could use some kind of mixing model to mix order-1 or order-(n-1) frequencies
 with any frequencies in the node that are high enough to suggest that they
 are more plentiful than in the order-(n-1) node.
\end_layout

\begin_layout Standard
- prune order-n nodes where their statistics are indistinguishable from
 parent node.
 This will save space without compromising compression performance.
 Relaxing 
\begin_inset Quotes eld
\end_inset

indistinguishable
\begin_inset Quotes erd
\end_inset

 to 
\begin_inset Quotes eld
\end_inset

very similar to
\begin_inset Quotes erd
\end_inset

 could save further space, but at some possible cost to compression.
\end_layout

\end_body
\end_document
